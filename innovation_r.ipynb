{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, Input\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = r\"IMU Dataset\\Data\"\n",
    "\n",
    "learnRate = 1e-4\n",
    "batchSize = 5\n",
    "patience = 4\n",
    "epoch = 200\n",
    "\n",
    "window_stride = 10\n",
    "sample_len = 100\n",
    "static_sample = 3\n",
    "features = 27\n",
    "static_features = 3\n",
    "volunteers = 30\n",
    "train_portion = 0.8\n",
    "val_portion = 0.9\n",
    "classes = 5\n",
    "\n",
    "trunk = 1\n",
    "thighR = 2\n",
    "thighL = 3\n",
    "shankR = 4\n",
    "shankL = 5\n",
    "wrist = 6\n",
    "\n",
    "headers = ['Acc_X', 'Acc_Y', 'Acc_Z', \n",
    "        'Gyr_X', 'Gyr_Y', 'Gyr_Z', \n",
    "        'Roll', 'Pitch', 'Yaw']\n",
    "\n",
    "norm = {'Acc_X': [-20.59292, 31.47302], \n",
    "        'Acc_Y': [-13.67152, 19.44969], \n",
    "        'Acc_Z': [-35.48537, 18.8095], \n",
    "        'Gyr_X': [-6.838557, 7.868352], \n",
    "        'Gyr_Y': [-16.90477, 16.61124], \n",
    "        'Gyr_Z': [-4.431263, 6.664771], \n",
    "        'Roll': [-207.2701, 214.6915], \n",
    "        'Pitch': [-89.953, 87.27671], \n",
    "        'Yaw': [-203.8373, 204.2526]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fixed(x, current_range, normed_range):\n",
    "    current_min, current_max = current_range\n",
    "    normed_min, normed_max = normed_range\n",
    "    x_normed = (x - current_min) / (current_max - current_min)\n",
    "    x_normed = x_normed * (normed_max - normed_min) + normed_min\n",
    "    return x_normed\n",
    "\n",
    "def trialLabel(num):\n",
    "    if num in range(4, 10):\n",
    "        return 0  # 'FE'\n",
    "    if num in [16, 18, 20, 22, 24, 26]:\n",
    "        return 1  # 'StrU'\n",
    "    if num in [17, 19, 21, 23, 25, 27]:\n",
    "        return 2  # 'StrD'\n",
    "    if num in [28, 30, 32, 34, 36, 38]:\n",
    "        return 3  # 'SlpU'\n",
    "    if num in [29, 31, 33, 35, 37, 39]:\n",
    "        return 4  # 'SlpD'\n",
    "    print('Check dataset!')\n",
    "\n",
    "\n",
    "def trialName(num):\n",
    "    if num in range(4, 10):\n",
    "        return 'FE: 0'\n",
    "    if num in [16, 18, 20, 22, 24, 26]:\n",
    "        return 'StrU: 1'\n",
    "    if num in [17, 19, 21, 23, 25, 27]:\n",
    "        return 'StrD: 2'\n",
    "    if num in [28, 30, 32, 34, 36, 38]:\n",
    "        return 'SlpU: 3'\n",
    "    if num in [29, 31, 33, 35, 37, 39]:\n",
    "        return 'SlpD: 4'\n",
    "    return False\n",
    "\n",
    "\n",
    "def trialInd(num):\n",
    "    if num == 0:\n",
    "        return 'FE: 0'\n",
    "    if num == 1:\n",
    "        return 'StrU: 1'\n",
    "    if num == 2:\n",
    "        return 'StrD: 2'\n",
    "    if num == 3:\n",
    "        return 'SlpU: 3'\n",
    "    if num == 4:\n",
    "        return 'SlpD: 4'\n",
    "    return False\n",
    "\n",
    "\n",
    "def openCSV(addr):\n",
    "    df = pd.read_csv(addr, sep=',', header=None)\n",
    "    header = df.iloc[0]\n",
    "    df = pd.DataFrame(df[1:], dtype=float)\n",
    "    df.columns = header\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved objects\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('Objects\\\\data', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(\"Loaded saved objects\")\n",
    "        \n",
    "except:\n",
    "    data = []\n",
    "    for person in range(0, volunteers):\n",
    "        tmp1 = []\n",
    "        print(person + 1, \"out of\", volunteers)\n",
    "        for trial in range(0, 57):\n",
    "            tmp2 = []\n",
    "            for sensor in range(0, 6):\n",
    "                tmp2.append(openCSV(address + f\"\\\\person{person + 1}_trial{trial + 1}_sensor{sensor + 1}.csv\"))\n",
    "            tmp1.append(tmp2)\n",
    "        data.append(tmp1)\n",
    "\n",
    "    with open(\"Objects\\\\data\", 'ab') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = {'Acc_X': [1e10, -1e10], 'Acc_Y': [1e10, -1e10], 'Acc_Z': [1e10, -1e10],\n",
    "#         'Gyr_X': [1e10, -1e10], 'Gyr_Y': [1e10, -1e10], 'Gyr_Z': [1e10, -1e10], \n",
    "#         'Roll': [1e10, -1e10], 'Pitch': [1e10, -1e10], 'Yaw': [1e10, -1e10]}\n",
    "\n",
    "# for person in range(0, volunteers):\n",
    "#     for trial in list(range(3, 9)) + list(range(15, 39)):\n",
    "#         flag = False\n",
    "#         for i in range(samplePerTrial):\n",
    "#             for sample in range(i * sampleLen, sampleLen + i * sampleLen):\n",
    "#                 for sensor in range(1, 5):\n",
    "#                     if flag:\n",
    "#                         break\n",
    "#                     if len(data[person][trial][sensor]) < optLen:\n",
    "#                         flag = True\n",
    "#                         continue\n",
    "#                     for para in ['Acc_X', 'Acc_Y', 'Acc_Z', \n",
    "#                                 'Gyr_X', 'Gyr_Y', 'Gyr_Z', \n",
    "#                                 'Roll', 'Pitch', 'Yaw']:\n",
    "#                         if data[person][trial][sensor][para].values[sample] > dic[para][1]:\n",
    "#                             dic[para][1] = data[person][trial][sensor][para].values[sample]\n",
    "#                         elif data[person][trial][sensor][para].values[sample] < dic[para][0]:\n",
    "#                             dic[para][0] = data[person][trial][sensor][para].values[sample]\n",
    "\n",
    "# print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = {'AGE': [1e10, -1e10], 'HEIGHT': [1e10, -1e10], 'WEIGHT': [1e10, -1e10],\n",
    "        'BMI': [1e10, -1e10], 'BMR': [1e10, -1e10], 'BSA': [1e10, -1e10]}\n",
    "height_average = 169.3\n",
    "height_sd = 21.5\n",
    "weight_average = 70.9\n",
    "weight_sd = 13.9\n",
    "subjects = []\n",
    "\n",
    "with open('subjects.txt') as f:\n",
    "    for r in f:\n",
    "        r = r.split()\n",
    "\n",
    "        bmi = float(r[4]) / (float(r[3]) / 100) ** 2\n",
    "        if r[2] == \"M\":\n",
    "            bmr = 88.362 + (13.397 * float(r[4])) + (4.799 * float(r[3])) - (5.677 * float(r[1]))\n",
    "        else:\n",
    "            bmr = 447.593 + (9.247 * float(r[4])) + (3.098 * float(r[3])) - (4.330 * float(r[1]))\n",
    "        bsa = float(r[3]) * float(r[4]) / 3600\n",
    "        sigma_h = 1 if abs(float(r[3]) - height_average) <= height_sd else 0\n",
    "        sigma_w = 1 if abs(float(r[4]) - weight_average) <= weight_sd else 0\n",
    "        subjects.append([[float(r[1]), float(r[3]), float(r[4])], [bmi, bmr, bsa], [sigma_h, sigma_w, 1.0 if r[2] == 'F' else 0.0]])\n",
    "\n",
    "        if float(r[1]) < dic2['AGE'][0]:\n",
    "            dic2['AGE'][0] = float(r[1])\n",
    "        if float(r[1]) > dic2['AGE'][1]:\n",
    "            dic2['AGE'][1] = float(r[1])\n",
    "\n",
    "        if float(r[3]) < dic2['HEIGHT'][0]:\n",
    "            dic2['HEIGHT'][0] = float(r[3])\n",
    "        if float(r[3]) > dic2['HEIGHT'][1]:\n",
    "            dic2['HEIGHT'][1] = float(r[3])\n",
    "\n",
    "        if float(r[4]) < dic2['WEIGHT'][0]:\n",
    "            dic2['WEIGHT'][0] = float(r[4])\n",
    "        if float(r[4]) > dic2['WEIGHT'][1]:\n",
    "            dic2['WEIGHT'][1] = float(r[4])\n",
    "\n",
    "        if bmi < dic2['BMI'][0]:\n",
    "            dic2['BMI'][0] = bmi\n",
    "        if bmi > dic2['BMI'][1]:\n",
    "            dic2['BMI'][1] = bmi\n",
    "\n",
    "        if bmr < dic2['BMR'][0]:\n",
    "            dic2['BMR'][0] = bmr\n",
    "        if bmr > dic2['BMR'][1]:\n",
    "            dic2['BMR'][1] = bmr\n",
    "\n",
    "        if bsa < dic2['BSA'][0]:\n",
    "            dic2['BSA'][0] = bsa\n",
    "        if bsa > dic2['BSA'][1]:\n",
    "            dic2['BSA'][1] = bsa\n",
    "\n",
    "for i in range(len(subjects)):\n",
    "    subjects[i][0][0] = normalize_fixed(subjects[i][0][0], [dic2['AGE'][0], dic2['AGE'][1]], [-1, 1])\n",
    "    subjects[i][0][1] = normalize_fixed(subjects[i][0][1], [dic2['HEIGHT'][0], dic2['HEIGHT'][1]], [-1, 1])\n",
    "    subjects[i][0][2] = normalize_fixed(subjects[i][0][2], [dic2['WEIGHT'][0], dic2['WEIGHT'][1]], [-1, 1])\n",
    "    subjects[i][1][0] = normalize_fixed(subjects[i][1][0], [dic2['BMI'][0], dic2['BMI'][1]], [-1, 1])\n",
    "    subjects[i][1][1] = normalize_fixed(subjects[i][1][1], [dic2['BMR'][0], dic2['BMR'][1]], [-1, 1])\n",
    "    subjects[i][1][2] = normalize_fixed(subjects[i][1][2], [dic2['BSA'][0], dic2['BSA'][1]], [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 30\n",
      "2 out of 30\n",
      "3 out of 30\n",
      "4 out of 30\n",
      "5 out of 30\n",
      "6 out of 30\n",
      "7 out of 30\n",
      "8 out of 30\n",
      "9 out of 30\n",
      "10 out of 30\n",
      "11 out of 30\n",
      "12 out of 30\n",
      "13 out of 30\n",
      "14 out of 30\n",
      "15 out of 30\n",
      "16 out of 30\n",
      "17 out of 30\n",
      "18 out of 30\n",
      "19 out of 30\n",
      "20 out of 30\n",
      "21 out of 30\n",
      "22 out of 30\n",
      "23 out of 30\n",
      "24 out of 30\n",
      "25 out of 30\n",
      "26 out of 30\n",
      "27 out of 30\n",
      "28 out of 30\n",
      "29 out of 30\n",
      "30 out of 30\n",
      "0\n",
      "300000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('Objects\\\\inputs_r', 'rb') as f:\n",
    "        inputs = np.load(f)\n",
    "    with open('Objects\\\\targets_r', 'rb') as f:\n",
    "        targets = pickle.load(f)\n",
    "    with open('Objects\\\\statics_r', 'rb') as f:\n",
    "        statics = pickle.load(f)\n",
    "    print(\"Loaded saved objects\")\n",
    "        \n",
    "except:\n",
    "    inputs = np.empty((300000, sample_len, features), dtype=float)\n",
    "    targets = []\n",
    "    statics = []\n",
    "    counter = 0\n",
    "    errors = 0\n",
    "\n",
    "    for person in range(0, volunteers):\n",
    "        print(person + 1, \"out of\", volunteers)\n",
    "        for trial in list(range(3, 9)) + list(range(15, 39)):\n",
    "            opt_len = min([len(data[person][trial][s]) for s in range(5)])\n",
    "            for i in range(0, opt_len - sample_len, window_stride):\n",
    "                for sample in range(i, i + sample_len):\n",
    "                    for sensor in [0, 1, 3]:\n",
    "                        for ind, para in enumerate(headers):\n",
    "                            raw_data = data[person][trial][sensor][para].values[sample]\n",
    "                            if not np.isfinite(raw_data):\n",
    "                                raw_data = 0\n",
    "                                errors += 1\n",
    "                            norm_data = normalize_fixed(raw_data, norm[para], [-1, 1])\n",
    "                            if sensor == 3:\n",
    "                                inputs[counter][sample - i][ind + len(headers) * 2] = norm_data\n",
    "                            else:\n",
    "                                inputs[counter][sample - i][ind + len(headers) * sensor] = norm_data\n",
    "                targets.append(int(trialLabel(trial + 1)))\n",
    "                statics.append([subjects[person]])\n",
    "                counter += 1\n",
    "\n",
    "    print(errors)   \n",
    "\n",
    "    inputs = inputs[:counter]\n",
    "    with open(\"Objects\\\\inputs_r\", 'ab') as f:\n",
    "        np.save(f, inputs)\n",
    "    with open(\"Objects\\\\targets_r\", 'ab') as f:\n",
    "        pickle.dump(targets, f)\n",
    "    with open(\"Objects\\\\statics_r\", 'ab') as f:\n",
    "        pickle.dump(statics, f)\n",
    "\n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14141, 100, 27) (14141, 1, 4) (14141, 5)\n"
     ]
    }
   ],
   "source": [
    "inputs2, statics2, targets2 = shuffle(inputs, statics, targets)\n",
    "\n",
    "del inputs\n",
    "del targets\n",
    "del statics\n",
    "\n",
    "statics2 = tf.convert_to_tensor(statics2)\n",
    "targets2 = tf.one_hot(targets2, classes)\n",
    "\n",
    "train = inputs2[:int(train_portion * len(inputs2))]\n",
    "train_s = statics2[:int(train_portion * len(inputs2))]\n",
    "train_label = targets2[:int(train_portion * len(inputs2))]\n",
    "\n",
    "val = inputs2[int(train_portion * len(inputs2)):int(val_portion * len(inputs2))]\n",
    "val_s = statics2[int(train_portion * len(inputs2)):int(val_portion * len(inputs2))]\n",
    "val_label = targets2[int(train_portion * len(inputs2)):int(val_portion * len(inputs2))]\n",
    "\n",
    "test = inputs2[int(val_portion * len(inputs2)):]\n",
    "test_s = statics2[int(val_portion * len(inputs2)):]\n",
    "test_label = targets2[int(val_portion * len(inputs2)):]\n",
    "\n",
    "del inputs2\n",
    "del targets2\n",
    "del statics2\n",
    "\n",
    "print(test.shape, test_s.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "22626/22626 [==============================] - 293s 13ms/step - loss: 0.4118 - accuracy: 0.8508 - val_loss: 0.2704 - val_accuracy: 0.9006\n",
      "Epoch 2/200\n",
      "22626/22626 [==============================] - 286s 13ms/step - loss: 0.2220 - accuracy: 0.9241 - val_loss: 0.1813 - val_accuracy: 0.9356\n",
      "Epoch 3/200\n",
      "22626/22626 [==============================] - 270s 12ms/step - loss: 0.1641 - accuracy: 0.9454 - val_loss: 0.1401 - val_accuracy: 0.9527\n",
      "Epoch 4/200\n",
      "22626/22626 [==============================] - 282s 12ms/step - loss: 0.1318 - accuracy: 0.9565 - val_loss: 0.1149 - val_accuracy: 0.9604\n",
      "Epoch 5/200\n",
      "22626/22626 [==============================] - 283s 13ms/step - loss: 0.1113 - accuracy: 0.9636 - val_loss: 0.1023 - val_accuracy: 0.9658\n",
      "Epoch 6/200\n",
      "22626/22626 [==============================] - 266s 12ms/step - loss: 0.0971 - accuracy: 0.9676 - val_loss: 0.0921 - val_accuracy: 0.9681\n",
      "Epoch 7/200\n",
      "22626/22626 [==============================] - 284s 13ms/step - loss: 0.0861 - accuracy: 0.9709 - val_loss: 0.0860 - val_accuracy: 0.9711\n",
      "Epoch 8/200\n",
      "22626/22626 [==============================] - 286s 13ms/step - loss: 0.0777 - accuracy: 0.9735 - val_loss: 0.0768 - val_accuracy: 0.9738\n",
      "Epoch 9/200\n",
      "22626/22626 [==============================] - 271s 12ms/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 0.0700 - val_accuracy: 0.9762\n",
      "Epoch 10/200\n",
      "22626/22626 [==============================] - 266s 12ms/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 0.0635 - val_accuracy: 0.9786\n",
      "Epoch 11/200\n",
      "22626/22626 [==============================] - 282s 12ms/step - loss: 0.0602 - accuracy: 0.9791 - val_loss: 0.0610 - val_accuracy: 0.9782\n",
      "Epoch 12/200\n",
      "22626/22626 [==============================] - 286s 13ms/step - loss: 0.0558 - accuracy: 0.9805 - val_loss: 0.0572 - val_accuracy: 0.9806\n",
      "Epoch 13/200\n",
      "22626/22626 [==============================] - 277s 12ms/step - loss: 0.0522 - accuracy: 0.9818 - val_loss: 0.0565 - val_accuracy: 0.9810\n",
      "Epoch 14/200\n",
      "22626/22626 [==============================] - 289s 13ms/step - loss: 0.0493 - accuracy: 0.9830 - val_loss: 0.0539 - val_accuracy: 0.9818\n",
      "Epoch 15/200\n",
      "22626/22626 [==============================] - 283s 13ms/step - loss: 0.0462 - accuracy: 0.9837 - val_loss: 0.0527 - val_accuracy: 0.9820\n",
      "Epoch 16/200\n",
      "22626/22626 [==============================] - 267s 12ms/step - loss: 0.0437 - accuracy: 0.9847 - val_loss: 0.0509 - val_accuracy: 0.9835\n",
      "Epoch 17/200\n",
      "22626/22626 [==============================] - 282s 12ms/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.0509 - val_accuracy: 0.9834\n",
      "Epoch 18/200\n",
      "22626/22626 [==============================] - 263s 12ms/step - loss: 0.0398 - accuracy: 0.9859 - val_loss: 0.0513 - val_accuracy: 0.9835\n",
      "Epoch 19/200\n",
      "22626/22626 [==============================] - 290s 13ms/step - loss: 0.0382 - accuracy: 0.9863 - val_loss: 0.0495 - val_accuracy: 0.9838\n",
      "Epoch 20/200\n",
      "22626/22626 [==============================] - 292s 13ms/step - loss: 0.0367 - accuracy: 0.9865 - val_loss: 0.0488 - val_accuracy: 0.9839\n",
      "Epoch 21/200\n",
      "22626/22626 [==============================] - 285s 13ms/step - loss: 0.0353 - accuracy: 0.9871 - val_loss: 0.0544 - val_accuracy: 0.9826\n",
      "Epoch 22/200\n",
      "22626/22626 [==============================] - 282s 12ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.0485 - val_accuracy: 0.9837\n",
      "Epoch 23/200\n",
      "22626/22626 [==============================] - 272s 12ms/step - loss: 0.0328 - accuracy: 0.9879 - val_loss: 0.0482 - val_accuracy: 0.9839\n",
      "Epoch 24/200\n",
      "22626/22626 [==============================] - 277s 12ms/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.0524 - val_accuracy: 0.9825\n",
      "Epoch 25/200\n",
      "22626/22626 [==============================] - 282s 12ms/step - loss: 0.0309 - accuracy: 0.9885 - val_loss: 0.0448 - val_accuracy: 0.9854\n",
      "Epoch 26/200\n",
      "22626/22626 [==============================] - 285s 13ms/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 0.0465 - val_accuracy: 0.9849\n",
      "Epoch 27/200\n",
      "22626/22626 [==============================] - 285s 13ms/step - loss: 0.0293 - accuracy: 0.9890 - val_loss: 0.0408 - val_accuracy: 0.9868\n",
      "Epoch 28/200\n",
      "22626/22626 [==============================] - 270s 12ms/step - loss: 0.0287 - accuracy: 0.9894 - val_loss: 0.0406 - val_accuracy: 0.9868\n",
      "Epoch 29/200\n",
      "22626/22626 [==============================] - 286s 13ms/step - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.0405 - val_accuracy: 0.9867\n",
      "Epoch 30/200\n",
      "22626/22626 [==============================] - 285s 13ms/step - loss: 0.0268 - accuracy: 0.9899 - val_loss: 0.0385 - val_accuracy: 0.9868\n",
      "Epoch 31/200\n",
      "22626/22626 [==============================] - 271s 12ms/step - loss: 0.0265 - accuracy: 0.9900 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 32/200\n",
      "22626/22626 [==============================] - 266s 12ms/step - loss: 0.0257 - accuracy: 0.9902 - val_loss: 0.0402 - val_accuracy: 0.9871\n",
      "Epoch 33/200\n",
      "22626/22626 [==============================] - 280s 12ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.0385 - val_accuracy: 0.9869\n",
      "Epoch 34/200\n",
      "22626/22626 [==============================] - 285s 13ms/step - loss: 0.0247 - accuracy: 0.9904 - val_loss: 0.0390 - val_accuracy: 0.9873\n",
      "Epoch 35/200\n",
      "22626/22626 [==============================] - 274s 12ms/step - loss: 0.0235 - accuracy: 0.9910 - val_loss: 0.0414 - val_accuracy: 0.9869\n",
      "Epoch 36/200\n",
      "22626/22626 [==============================] - 266s 12ms/step - loss: 0.0233 - accuracy: 0.9908 - val_loss: 0.0402 - val_accuracy: 0.9871\n",
      "Epoch 37/200\n",
      "22626/22626 [==============================] - 267s 12ms/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.0406 - val_accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### LSTM + CNN\n",
    "# try:\n",
    "#     model_rnn = models.load_model('model')\n",
    "\n",
    "# except Exception as e:\n",
    "time_series_input = Input(shape=(sample_len, features))\n",
    "static_input = Input(shape=(static_sample, static_features))\n",
    "\n",
    "lstm = layers.LSTM(32, return_sequences=True)(time_series_input)\n",
    "static1 = layers.Conv1D(32, 2, strides=1, activation=tf.nn.relu)(static_input)\n",
    "static2 = layers.MaxPooling1D(pool_size=2, strides=1)(static1)\n",
    "\n",
    "main = layers.Concatenate(axis= 1)([lstm, static2])\n",
    "flat = layers.Flatten()(main)\n",
    "out = layers.Dense(classes, activation='softmax')(flat)\n",
    "\n",
    "model_rnn = models.Model(inputs=[time_series_input, static_input],\n",
    "                            outputs=out)\n",
    "\n",
    "model_rnn.compile(optimizer=optimizers.Adam(learning_rate=learnRate), \n",
    "                metrics=['accuracy'],\n",
    "                loss=losses.CategoricalCrossentropy(from_logits=False))\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "history_rnn = model_rnn.fit([train, train_s], train_label, batch_size=batchSize, epochs=epoch, \n",
    "                            validation_data=([val, val_s], val_label), callbacks=[earlyStop], shuffle=False)\n",
    "\n",
    "plt.plot(history_rnn.history['accuracy'], 'b-.', label=\"LSTM Training Accuracy\")\n",
    "plt.plot(history_rnn.history['val_accuracy'], 'r-.', label=\"LSTM Validation Accuracy\")\n",
    "plt.plot(history_rnn.history['loss'], 'b.', label=\"LSTM Training Loss\")\n",
    "plt.plot(history_rnn.history['val_loss'], 'r.', label=\"LSTM Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_rnn.save('model_r')\n",
    "\n",
    "with open(\"test2\", 'ab') as f:\n",
    "    pickle.dump(test, f)\n",
    "with open(\"test_s2\", 'ab') as f:\n",
    "    pickle.dump(test_s, f)\n",
    "with open(\"test_label2\", 'ab') as f:\n",
    "    pickle.dump(test_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 4s 8ms/step - loss: 0.0364 - accuracy: 0.9873\n",
      "Test Accuracy LSTM: 98.73%\n"
     ]
    }
   ],
   "source": [
    "# with open('test', 'rb') as f:\n",
    "#     test = pickle.load(f)\n",
    "# with open('test_s', 'rb') as f:\n",
    "#     test_s = pickle.load(f)\n",
    "# with open('test_label', 'rb') as f:\n",
    "#     test_label = pickle.load(f)\n",
    "\n",
    "print(f\"Test Accuracy LSTM: {model_rnn.evaluate([test, test_s], test_label)[1] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
