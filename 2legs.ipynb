{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, Input\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = r\"IMU Dataset\\Data\"\n",
    "\n",
    "learnRate = 1e-4\n",
    "batchSize = 5\n",
    "patience = 4\n",
    "epoch = 200\n",
    "\n",
    "window_stride = 10\n",
    "sample_len = 200\n",
    "sample_per_trial = 5\n",
    "features = 45\n",
    "static_features = 4\n",
    "volunteers = 30\n",
    "train_portion = 0.8\n",
    "val_portion = 0.9\n",
    "classes = 5\n",
    "\n",
    "trunk = 1\n",
    "thighR = 2\n",
    "thighL = 3\n",
    "shankR = 4\n",
    "shankL = 5\n",
    "wrist = 6\n",
    "\n",
    "headers = ['Acc_X', 'Acc_Y', 'Acc_Z', \n",
    "        'Gyr_X', 'Gyr_Y', 'Gyr_Z', \n",
    "        'Roll', 'Pitch', 'Yaw']\n",
    "\n",
    "norm = {'Acc_X': [-20.59292, 31.47302], \n",
    "        'Acc_Y': [-13.67152, 19.44969], \n",
    "        'Acc_Z': [-35.48537, 18.8095], \n",
    "        'Gyr_X': [-6.838557, 7.868352], \n",
    "        'Gyr_Y': [-16.90477, 16.61124], \n",
    "        'Gyr_Z': [-4.431263, 6.664771], \n",
    "        'Roll': [-207.2701, 214.6915], \n",
    "        'Pitch': [-89.953, 87.27671], \n",
    "        'Yaw': [-203.8373, 204.2526]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fixed(x, current_range, normed_range):\n",
    "    current_min, current_max = current_range\n",
    "    normed_min, normed_max = normed_range\n",
    "    x_normed = (x - current_min) / (current_max - current_min)\n",
    "    x_normed = x_normed * (normed_max - normed_min) + normed_min\n",
    "    return x_normed\n",
    "\n",
    "def trialLabel(num):\n",
    "    if num in range(4, 10):\n",
    "        return 0  # 'FE'\n",
    "    if num in [16, 18, 20, 22, 24, 26]:\n",
    "        return 1  # 'StrU'\n",
    "    if num in [17, 19, 21, 23, 25, 27]:\n",
    "        return 2  # 'StrD'\n",
    "    if num in [28, 30, 32, 34, 36, 38]:\n",
    "        return 3  # 'SlpU'\n",
    "    if num in [29, 31, 33, 35, 37, 39]:\n",
    "        return 4  # 'SlpD'\n",
    "    print('Check dataset!')\n",
    "\n",
    "\n",
    "def trialName(num):\n",
    "    if num in range(4, 10):\n",
    "        return 'FE: 0'\n",
    "    if num in [16, 18, 20, 22, 24, 26]:\n",
    "        return 'StrU: 1'\n",
    "    if num in [17, 19, 21, 23, 25, 27]:\n",
    "        return 'StrD: 2'\n",
    "    if num in [28, 30, 32, 34, 36, 38]:\n",
    "        return 'SlpU: 3'\n",
    "    if num in [29, 31, 33, 35, 37, 39]:\n",
    "        return 'SlpD: 4'\n",
    "    return False\n",
    "\n",
    "\n",
    "def trialInd(num):\n",
    "    if num == 0:\n",
    "        return 'FE: 0'\n",
    "    if num == 1:\n",
    "        return 'StrU: 1'\n",
    "    if num == 2:\n",
    "        return 'StrD: 2'\n",
    "    if num == 3:\n",
    "        return 'SlpU: 3'\n",
    "    if num == 4:\n",
    "        return 'SlpD: 4'\n",
    "    return False\n",
    "\n",
    "\n",
    "def openCSV(addr):\n",
    "    df = pd.read_csv(addr, sep=',', header=None)\n",
    "    header = df.iloc[0]\n",
    "    df = pd.DataFrame(df[1:], dtype=float)\n",
    "    df.columns = header\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved objects\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('Objects\\\\data', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(\"Loaded saved objects\")\n",
    "        \n",
    "except:\n",
    "    data = []\n",
    "    for person in range(0, volunteers):\n",
    "        tmp1 = []\n",
    "        print(person + 1, \"out of\", volunteers)\n",
    "        for trial in range(0, 57):\n",
    "            tmp2 = []\n",
    "            for sensor in range(0, 6):\n",
    "                tmp2.append(openCSV(address + f\"\\\\person{person + 1}_trial{trial + 1}_sensor{sensor + 1}.csv\"))\n",
    "            tmp1.append(tmp2)\n",
    "        data.append(tmp1)\n",
    "\n",
    "    with open(\"Objects\\\\data\", 'ab') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = {'Acc_X': [1e10, -1e10], 'Acc_Y': [1e10, -1e10], 'Acc_Z': [1e10, -1e10],\n",
    "#         'Gyr_X': [1e10, -1e10], 'Gyr_Y': [1e10, -1e10], 'Gyr_Z': [1e10, -1e10], \n",
    "#         'Roll': [1e10, -1e10], 'Pitch': [1e10, -1e10], 'Yaw': [1e10, -1e10]}\n",
    "\n",
    "# for person in range(0, volunteers):\n",
    "#     for trial in list(range(3, 9)) + list(range(15, 39)):\n",
    "#         flag = False\n",
    "#         for i in range(samplePerTrial):\n",
    "#             for sample in range(i * sampleLen, sampleLen + i * sampleLen):\n",
    "#                 for sensor in range(1, 5):\n",
    "#                     if flag:\n",
    "#                         break\n",
    "#                     if len(data[person][trial][sensor]) < optLen:\n",
    "#                         flag = True\n",
    "#                         continue\n",
    "#                     for para in ['Acc_X', 'Acc_Y', 'Acc_Z', \n",
    "#                                 'Gyr_X', 'Gyr_Y', 'Gyr_Z', \n",
    "#                                 'Roll', 'Pitch', 'Yaw']:\n",
    "#                         if data[person][trial][sensor][para].values[sample] > dic[para][1]:\n",
    "#                             dic[para][1] = data[person][trial][sensor][para].values[sample]\n",
    "#                         elif data[person][trial][sensor][para].values[sample] < dic[para][0]:\n",
    "#                             dic[para][0] = data[person][trial][sensor][para].values[sample]\n",
    "\n",
    "# print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = {'AGE': [1e10, -1e10], 'HEIGHT': [1e10, -1e10], 'WEIGHT': [1e10, -1e10]}\n",
    "subjects = []\n",
    "\n",
    "with open('subjects.txt') as f:\n",
    "    for r in f:\n",
    "        r = r.split()\n",
    "        subjects.append([float(r[1]), float(r[3]), float(r[4]), 1.0 if r[2] == 'F' else 0.0])\n",
    "\n",
    "        if float(r[1]) < dic2['AGE'][0]:\n",
    "            dic2['AGE'][0] = float(r[1])\n",
    "        if float(r[1]) > dic2['AGE'][1]:\n",
    "            dic2['AGE'][1] = float(r[1])\n",
    "\n",
    "        if float(r[3]) < dic2['HEIGHT'][0]:\n",
    "            dic2['HEIGHT'][0] = float(r[3])\n",
    "        if float(r[3]) > dic2['HEIGHT'][1]:\n",
    "            dic2['HEIGHT'][1] = float(r[3])\n",
    "\n",
    "        if float(r[4]) < dic2['WEIGHT'][0]:\n",
    "            dic2['WEIGHT'][0] = float(r[4])\n",
    "        if float(r[4]) > dic2['WEIGHT'][1]:\n",
    "            dic2['WEIGHT'][1] = float(r[4])\n",
    "\n",
    "for i in range(len(subjects)):\n",
    "    subjects[i][0] = normalize_fixed(subjects[i][0], [dic2['AGE'][0], dic2['AGE'][1]], [-1, 1])\n",
    "    subjects[i][1] = normalize_fixed(subjects[i][1], [dic2['HEIGHT'][0], dic2['HEIGHT'][1]], [-1, 1])\n",
    "    subjects[i][2] = normalize_fixed(subjects[i][2], [dic2['WEIGHT'][0], dic2['WEIGHT'][1]], [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved objects\n",
      "132409\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('Objects\\\\inputs', 'rb') as f:\n",
    "        inputs = pickle.load(f)\n",
    "    with open('Objects\\\\targets', 'rb') as f:\n",
    "        targets = pickle.load(f)\n",
    "    with open('Objects\\\\statics', 'rb') as f:\n",
    "        statics = pickle.load(f)\n",
    "    print(\"Loaded saved objects\")\n",
    "        \n",
    "except:\n",
    "    inputs = np.empty((200000, sample_len, features), dtype=float)\n",
    "    targets = []\n",
    "    statics = []\n",
    "    counter = 0\n",
    "    errors = 0\n",
    "\n",
    "    for person in range(0, volunteers):\n",
    "        print(person + 1, \"out of\", volunteers)\n",
    "        for trial in list(range(3, 9)) + list(range(15, 39)):\n",
    "            opt_len = min([len(data[person][trial][s]) for s in range(5)])\n",
    "            for i in range(0, opt_len - sample_len, window_stride):\n",
    "                for sample in range(i, i + sample_len):\n",
    "                    for sensor in range(0, 5):\n",
    "                        for ind, para in enumerate(headers):\n",
    "                            raw_data = data[person][trial][sensor][para].values[sample]\n",
    "                            if not np.isfinite(raw_data):\n",
    "                                raw_data = 0\n",
    "                                errors += 1\n",
    "                            norm_data = normalize_fixed(raw_data, norm[para], [-1, 1])\n",
    "                            inputs[counter][sample - i][ind + len(headers) * sensor] = norm_data\n",
    "                targets.append(int(trialLabel(trial + 1)))\n",
    "                statics.append([subjects[person]])\n",
    "                counter += 1\n",
    "\n",
    "    print(errors)   \n",
    "\n",
    "    inputs = inputs[:counter]\n",
    "    with open(\"Objects\\\\inputs\", 'ab') as f:\n",
    "        pickle.dump(inputs, f)\n",
    "    with open(\"Objects\\\\targets\", 'ab') as f:\n",
    "        pickle.dump(targets, f)\n",
    "    with open(\"Objects\\\\statics\", 'ab') as f:\n",
    "        pickle.dump(statics, f)\n",
    "\n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13241, 200, 45) (13241, 1, 4) (13241, 5)\n"
     ]
    }
   ],
   "source": [
    "inputs2, statics2, targets2 = shuffle(inputs, statics, targets)\n",
    "\n",
    "del inputs\n",
    "del targets\n",
    "del statics\n",
    "\n",
    "statics2 = tf.convert_to_tensor(statics2)\n",
    "targets2 = tf.one_hot(targets2, classes)\n",
    "\n",
    "train = inputs2[:int(train_portion * len(inputs2))]\n",
    "train_s = statics2[:int(train_portion * len(inputs2))]\n",
    "train_label = targets2[:int(train_portion * len(inputs2))]\n",
    "\n",
    "val = inputs2[int(train_portion * len(inputs2)):int(val_portion * len(inputs2))]\n",
    "val_s = statics2[int(train_portion * len(inputs2)):int(val_portion * len(inputs2))]\n",
    "val_label = targets2[int(train_portion * len(inputs2)):int(val_portion * len(inputs2))]\n",
    "\n",
    "test = inputs2[int(val_portion * len(inputs2)):]\n",
    "test_s = statics2[int(val_portion * len(inputs2)):]\n",
    "test_label = targets2[int(val_portion * len(inputs2)):]\n",
    "\n",
    "del inputs2\n",
    "del targets2\n",
    "del statics2\n",
    "\n",
    "print(test.shape, test_s.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN\n",
    "\n",
    "model_cnn = models.Sequential()\n",
    "\n",
    "model_cnn.add(layers.Conv1D(18, 2, strides=2, activation=tf.nn.relu, input_shape=(sample_len, features)))\n",
    "model_cnn.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "model_cnn.add(layers.Conv1D(36, 2, strides=2, activation=tf.nn.relu))\n",
    "model_cnn.add(layers.MaxPooling1D(pool_size=2, strides=1))\n",
    "\n",
    "model_cnn.add(layers.Conv1D(72, 2, strides=2, activation=tf.nn.relu))\n",
    "model_cnn.add(layers.MaxPooling1D(pool_size=2, strides=1))\n",
    "\n",
    "model_cnn.add(layers.Conv1D(144, 2, strides=2, activation=tf.nn.relu))\n",
    "model_cnn.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "model_cnn.add(layers.BatchNormalization())\n",
    "model_cnn.add(layers.Dropout(0.5))\n",
    "\n",
    "model_cnn.add(layers.Flatten())\n",
    "model_cnn.add(layers.Dense(classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model_cnn.compile(optimizer=optimizers.Adam(learning_rate=learnRate), metrics=['accuracy'],\n",
    "            loss=losses.CategoricalCrossentropy(from_logits=False))\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "history_cnn = model_cnn.fit(train, train_label, batch_size=batchSize, epochs=epoch, \n",
    "                            validation_data=(val, val_label), callbacks=[earlyStop], shuffle=False)\n",
    "\n",
    "\n",
    "### LSTM\n",
    "model_rnn = models.Sequential()\n",
    "\n",
    "model_rnn.add(layers.LSTM(32, return_sequences=True, input_shape=(sample_len, features)))\n",
    "\n",
    "model_rnn.add(layers.Flatten())\n",
    "\n",
    "model_rnn.add(layers.Dense(classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model_rnn.compile(optimizer=optimizers.Adam(learning_rate=learnRate), \n",
    "                metrics=['accuracy'],\n",
    "                loss=losses.CategoricalCrossentropy(from_logits=False))\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "history_rnn = model_rnn.fit(train, train_label, batch_size=batchSize, epochs=epoch, \n",
    "                            validation_data=(val, val_label), callbacks=[earlyStop], shuffle=False)\n",
    "\n",
    "\n",
    "plt.plot(history_cnn.history['accuracy'], 'b:', label=\"CNN Training Accuracy\")\n",
    "plt.plot(history_cnn.history['val_accuracy'], 'r:', label=\"CNN Validation Accuracy\")\n",
    "plt.plot(history_rnn.history['accuracy'], 'b-.', label=\"LSTM Training Accuracy\")\n",
    "plt.plot(history_rnn.history['val_accuracy'], 'r-.', label=\"LSTM Validation Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Test Accuracy CNN: {model_cnn.evaluate(test, test_label)[1] * 100:.2f}%\")\n",
    "print(f\"Test Accuracy LSTM: {model_rnn.evaluate(test, test_label)[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM + SLP\n",
    "time_series_input = Input(shape=(sample_len, features))\n",
    "static_input = Input(shape=(1, static_features))\n",
    "\n",
    "lstm = layers.LSTM(32, return_sequences=True)(time_series_input)\n",
    "static = layers.Dense(32, activation='relu')(static_input)\n",
    "\n",
    "main = layers.Concatenate(axis= 1)([lstm, static])\n",
    "flat = layers.Flatten()(main)\n",
    "out = layers.Dense(classes, activation='softmax')(flat)\n",
    "\n",
    "\n",
    "model_rnn = models.Model(inputs=[time_series_input, static_input],\n",
    "                            outputs=out)\n",
    "\n",
    "model_rnn.compile(optimizer=optimizers.Adam(learning_rate=learnRate), \n",
    "                metrics=['accuracy'],\n",
    "                loss=losses.CategoricalCrossentropy(from_logits=False))\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "history_rnn = model_rnn.fit([train, train_s], train_label, batch_size=batchSize, epochs=epoch, \n",
    "                            validation_data=([val, val_s], val_label), callbacks=[earlyStop], shuffle=False)\n",
    "\n",
    "\n",
    "plt.plot(history_rnn.history['accuracy'], 'b-.', label=\"LSTM Training Accuracy\")\n",
    "plt.plot(history_rnn.history['val_accuracy'], 'r-.', label=\"LSTM Validation Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Test Accuracy LSTM: {model_rnn.evaluate([test, test_s], test_label)[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21186/21186 [==============================] - 337s 15ms/step - loss: 0.2006 - accuracy: 0.9290 - val_loss: 0.0773 - val_accuracy: 0.9773\n",
      "Epoch 2/200\n",
      "21186/21186 [==============================] - 325s 15ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.0458 - val_accuracy: 0.9866\n",
      "Epoch 3/200\n",
      "21186/21186 [==============================] - 326s 15ms/step - loss: 0.0398 - accuracy: 0.9871 - val_loss: 0.0320 - val_accuracy: 0.9900\n",
      "Epoch 4/200\n",
      "21186/21186 [==============================] - 320s 15ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0298 - val_accuracy: 0.9906\n",
      "Epoch 5/200\n",
      "21186/21186 [==============================] - 320s 15ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0289 - val_accuracy: 0.9906\n",
      "Epoch 6/200\n",
      "21186/21186 [==============================] - 321s 15ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0291 - val_accuracy: 0.9897\n",
      "Epoch 7/200\n",
      "21186/21186 [==============================] - 323s 15ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.0196 - val_accuracy: 0.9923\n",
      "Epoch 8/200\n",
      "21186/21186 [==============================] - 324s 15ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 0.0195 - val_accuracy: 0.9926\n",
      "Epoch 9/200\n",
      "21186/21186 [==============================] - 322s 15ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0215 - val_accuracy: 0.9920\n",
      "Epoch 10/200\n",
      "21186/21186 [==============================] - 321s 15ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.0187 - val_accuracy: 0.9929\n",
      "Epoch 11/200\n",
      "21186/21186 [==============================] - 325s 15ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0225 - val_accuracy: 0.9928\n",
      "Epoch 12/200\n",
      "21186/21186 [==============================] - 314s 15ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.0182 - val_accuracy: 0.9934\n",
      "Epoch 13/200\n",
      "21186/21186 [==============================] - 302s 14ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.0167 - val_accuracy: 0.9937\n",
      "Epoch 14/200\n",
      "21186/21186 [==============================] - 311s 15ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.0240 - val_accuracy: 0.9915\n",
      "Epoch 15/200\n",
      "21186/21186 [==============================] - 313s 15ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.0176 - val_accuracy: 0.9935\n",
      "Epoch 16/200\n",
      "21186/21186 [==============================] - 311s 15ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "Epoch 17/200\n",
      "21186/21186 [==============================] - 311s 15ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0161 - val_accuracy: 0.9940\n",
      "Epoch 18/200\n",
      "21186/21186 [==============================] - 313s 15ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.0173 - val_accuracy: 0.9941\n",
      "Epoch 19/200\n",
      "21186/21186 [==============================] - 312s 15ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.0169 - val_accuracy: 0.9942\n",
      "Epoch 20/200\n",
      "21186/21186 [==============================] - 313s 15ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.0165 - val_accuracy: 0.9934\n",
      "Epoch 21/200\n",
      "21186/21186 [==============================] - 312s 15ms/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 0.0148 - val_accuracy: 0.9940\n",
      "Epoch 22/200\n",
      "21186/21186 [==============================] - 312s 15ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.0171 - val_accuracy: 0.9942\n",
      "Epoch 23/200\n",
      "21186/21186 [==============================] - 313s 15ms/step - loss: 0.0126 - accuracy: 0.9950 - val_loss: 0.0191 - val_accuracy: 0.9933\n",
      "Epoch 24/200\n",
      "21186/21186 [==============================] - 312s 15ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0152 - val_accuracy: 0.9938\n",
      "Epoch 25/200\n",
      "21186/21186 [==============================] - 312s 15ms/step - loss: 0.0121 - accuracy: 0.9952 - val_loss: 0.0192 - val_accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### LSTM + CNN\n",
    "# try:\n",
    "#     model_rnn = models.load_model('model')\n",
    "\n",
    "# except Exception as e:\n",
    "time_series_input = Input(shape=(sample_len, features))\n",
    "static_input = Input(shape=(1, static_features))\n",
    "\n",
    "lstm = layers.LSTM(32, return_sequences=True)(time_series_input)\n",
    "static1 = layers.Conv1D(32, 1, strides=1, activation=tf.nn.relu)(static_input)\n",
    "static2 = layers.MaxPooling1D(pool_size=1, strides=1)(static1)\n",
    "\n",
    "main = layers.Concatenate(axis= 1)([lstm, static2])\n",
    "flat = layers.Flatten()(main)\n",
    "out = layers.Dense(classes, activation='softmax')(flat)\n",
    "\n",
    "\n",
    "model_rnn = models.Model(inputs=[time_series_input, static_input],\n",
    "                            outputs=out)\n",
    "\n",
    "model_rnn.compile(optimizer=optimizers.Adam(learning_rate=learnRate), \n",
    "                metrics=['accuracy'],\n",
    "                loss=losses.CategoricalCrossentropy(from_logits=False))\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "history_rnn = model_rnn.fit([train, train_s], train_label, batch_size=batchSize, epochs=epoch, \n",
    "                            validation_data=([val, val_s], val_label), callbacks=[earlyStop], shuffle=False)\n",
    "\n",
    "\n",
    "plt.plot(history_rnn.history['accuracy'], 'b-.', label=\"LSTM Training Accuracy\")\n",
    "plt.plot(history_rnn.history['val_accuracy'], 'r-.', label=\"LSTM Validation Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_rnn.save('model2')\n",
    "\n",
    "with open(\"test2\", 'ab') as f:\n",
    "    pickle.dump(test, f)\n",
    "with open(\"test_s2\", 'ab') as f:\n",
    "    pickle.dump(test_s, f)\n",
    "with open(\"test_label2\", 'ab') as f:\n",
    "    pickle.dump(test_label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - 8s 9ms/step - loss: 0.0234 - accuracy: 0.9918\n",
      "Test Accuracy LSTM: 99.18%\n"
     ]
    }
   ],
   "source": [
    "with open('test', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open('test_s', 'rb') as f:\n",
    "    test_s = pickle.load(f)\n",
    "with open('test_label', 'rb') as f:\n",
    "    test_label = pickle.load(f)\n",
    "\n",
    "print(f\"Test Accuracy LSTM: {model_rnn.evaluate([test, test_s], test_label)[1] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
